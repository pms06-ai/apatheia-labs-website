<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Quality Control Comparison Matrix | Research Hub | Phronesis</title>
  <meta name="description" content="Comprehensive comparison of quality control, peer review, and validation techniques used across six professional investigation domains.">
  <meta property="og:title" content="Quality Control Comparison Matrix | Phronesis Research Hub">
  <meta property="og:description" content="Comprehensive comparison of quality control, peer review, and validation techniques used across six professional investigation domains.">
  <meta property="og:type" content="article">
  <meta property="og:image" content="https://apatheialabs.com/og-image.png">
  <link rel="canonical" href="https://apatheialabs.com/research/QUALITY-CONTROL-COMPARISON/">
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <script defer data-domain="apatheialabs.com" src="https://plausible.io/js/script.js"></script>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Playfair+Display:ital,wght@0,400;0,500;0,600;1,400&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="/research/article.css">
</head>
<body>
  <header>
    <div class="container">
      <a href="/" class="logo">
        <div class="logo-icon">A</div>
        <div class="logo-text">
          <span class="logo-brand">APATHEIA LABS</span>
          <span class="logo-tagline">Clarity Without Distortion</span>
        </div>
      </a>
      <nav>
        <a href="/#about">About</a>
        <a href="/#methodology">Methodology</a>
        <a href="/research/" class="active">Research</a>
        <a href="https://github.com/apatheia-labs/phronesis" target="_blank" rel="noopener noreferrer">GitHub</a>
        <a href="/#download" class="btn btn-primary">Download</a>
      </nav>
      <button class="mobile-menu-btn" aria-label="Menu">
        <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
          <path d="M3 12h18M3 6h18M3 18h18"/>
        </svg>
      </button>
    </div>
  </header>


  <main>
    <section class="doc-hero">
      <div class="container">
        <div class="doc-hero-content">
          <div class="breadcrumbs">Research</div>
          <h1 class="doc-title">Quality Control Comparison Matrix</h1>
          <p class="doc-description">Comprehensive comparison of quality control, peer review, and validation techniques used across six professional investigation domains.</p>
          <div class="doc-meta">
            <span>Quality Control</span>
            <span>Complete</span>
            <span>Open Source</span>
          </div>
        </div>
      </div>
    </section>

    <section>
      <div class="container doc-layout">
        <aside class="doc-toc">
          <div class="doc-toc-title">Contents</div>
          <nav id="TOC">
            <ul>
<li><a href="#quality-control-approaches-across-investigation-methodologies">Quality Control Approaches Across Investigation Methodologies</a></li>
<ul>
<li><a href="#purpose">Purpose</a></li>
<li><a href="#visual-comparison-matrix">Visual Comparison Matrix</a></li>
<ul>
<li><a href="#quality-control-dimensions">Quality Control Dimensions</a></li>
</ul>
<li><a href="#detailed-comparison">Detailed Comparison</a></li>
<ul>
<li><a href="#1-police-investigation-quality-control">1. Police Investigation Quality Control</a></li>
<li><a href="#2-journalism-quality-control">2. Journalism Quality Control</a></li>
<li><a href="#3-legal-ediscovery-quality-control">3. Legal eDiscovery Quality Control</a></li>
<li><a href="#4-regulatory-investigation-quality-control">4. Regulatory Investigation Quality Control</a></li>
<li><a href="#5-intelligence-analysis-quality-control">5. Intelligence Analysis Quality Control</a></li>
<li><a href="#6-academic-research-quality-control">6. Academic Research Quality Control</a></li>
</ul>
<li><a href="#cross-domain-quality-control-patterns">Cross-Domain Quality Control Patterns</a></li>
<ul>
<li><a href="#universal-principles">Universal Principles</a></li>
<li><a href="#convergent-practices">Convergent Practices</a></li>
</ul>
<li><a href="#implementation-for-phronesis-fcip">Implementation for Phronesis FCIP</a></li>
<ul>
<li><a href="#recommended-multi-layered-qc-architecture">Recommended Multi-Layered QC Architecture</a></li>
<li><a href="#qc-metrics-dashboard">QC Metrics Dashboard</a></li>
<li><a href="#decision-rules">Decision Rules</a></li>
</ul>
<li><a href="#cost-benefit-analysis">Cost-Benefit Analysis</a></li>
<ul>
<li><a href="#time-investment-typical">Time Investment (Typical)</a></li>
<li><a href="#error-cost-vs-qc-cost-trade-off">Error Cost vs. QC Cost Trade-off</a></li>
</ul>
<li><a href="#selecting-qc-methodology">Selecting QC Methodology</a></li>
<ul>
<li><a href="#decision-tree">Decision Tree</a></li>
</ul>
<li><a href="#quality-control-integration-with-sam-framework">Quality Control Integration with S.A.M. Framework</a></li>
<ul>
<li><a href="#qc-for-each-contradiction-type">QC for Each Contradiction Type</a></li>
</ul>
<li><a href="#continuous-improvement">Continuous Improvement</a></li>
<ul>
<li><a href="#qc-metrics-to-track">QC Metrics to Track</a></li>
<li><a href="#calibration-protocol">Calibration Protocol</a></li>
</ul>
<li><a href="#further-reading">Further Reading</a></li>
</ul>
</ul>
          </nav>
        </aside>
        <article class="doc-content">
          <h1 id="quality-control-approaches-across-investigation-methodologies">Quality Control Approaches Across Investigation Methodologies</h1>
<p>Comprehensive comparison of quality control, peer review, and validation techniques used across six professional investigation domains.</p>
<h2 id="purpose">Purpose</h2>
<p>This reference document enables:</p>
<ul>
<li>Selection of appropriate QC methods for different investigation types</li>
<li>Cross-validation using multiple quality control frameworks</li>
<li>Implementation of multi-layered quality assurance</li>
<li>Understanding trade-offs between rigor, speed, and cost</li>
</ul>
<h2 id="visual-comparison-matrix">Visual Comparison Matrix</h2>
<h3 id="quality-control-dimensions">Quality Control Dimensions</h3>
<table>
<thead>
<tr>
<th>Domain</th>
<th>Primary QC Method</th>
<th>Validation Standard</th>
<th>Min. Reviewers</th>
<th>Statistical Measure</th>
<th>Time to QC</th>
<th>Cost Impact</th>
<th>Defensibility</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Police</strong></td>
<td>Supervisory oversight</td>
<td>IOPC standards</td>
<td>1-2 (supervisor + peer)</td>
<td>N/A</td>
<td>Days-weeks</td>
<td>üü¢ Low</td>
<td>üü¢ High (court-tested)</td>
</tr>
<tr>
<td><strong>Journalism</strong></td>
<td>Multi-layered editorial</td>
<td>Magazine model fact-checking</td>
<td>3-5 (writer, editor, fact-checker, legal)</td>
<td>N/A</td>
<td>Weeks-months</td>
<td>üî¥ High</td>
<td>üü° Medium (reputation)</td>
</tr>
<tr>
<td><strong>Legal</strong></td>
<td>Statistical sampling</td>
<td>TAR validation (75%+ recall)</td>
<td>2+ (QC reviewer + senior attorney)</td>
<td>Precision/Recall metrics</td>
<td>Days-weeks</td>
<td>üü° Medium (automated)</td>
<td>üü¢ High (court-approved)</td>
</tr>
<tr>
<td><strong>Regulatory</strong></td>
<td>Dual decision-makers</td>
<td>Real prospect test</td>
<td>2 (professional + lay)</td>
<td>N/A</td>
<td>Months</td>
<td>üü¢ Low</td>
<td>üü¢ High (statutory)</td>
</tr>
<tr>
<td><strong>Intelligence</strong></td>
<td>Structured review</td>
<td>ICD 203 tradecraft standards</td>
<td>3+ (analyst + reviewer + Red Cell)</td>
<td>N/A</td>
<td>Days-weeks</td>
<td>üü° Medium</td>
<td>üü° Medium (classified)</td>
</tr>
<tr>
<td><strong>Academic</strong></td>
<td>Inter-rater reliability</td>
<td>Cohen&#39;s Kappa ‚â•0.60</td>
<td>2-3 (dual independent coding)</td>
<td>Kappa, ICC</td>
<td>Weeks-months</td>
<td>üü° Medium</td>
<td>üü¢ High (peer-reviewed)</td>
</tr>
</tbody></table>
<p><strong>Legend:</strong></p>
<ul>
<li>üü¢ Low/High (favorable) | üü° Medium | üî¥ High/Low (challenging)</li>
</ul>
<hr>
<h2 id="detailed-comparison">Detailed Comparison</h2>
<h3 id="1-police-investigation-quality-control">1. Police Investigation Quality Control</h3>
<p><strong>Framework:</strong> Three-tier supervisory oversight</p>
<ul>
<li><strong>First-line supervisor</strong> (Sergeant): Reviews all investigations, checks procedure compliance</li>
<li><strong>Peer review</strong>: Fellow investigators review complex cases</li>
<li><strong>Professional Standards Department</strong>: Monitors for misconduct/negligence</li>
</ul>
<p><strong>IOPC Standards:</strong></p>
<ul>
<li>Independent oversight for serious incidents</li>
<li>Mandatory referrals for deaths/serious injuries</li>
<li>Transparency requirements</li>
<li>Public reporting</li>
</ul>
<p><strong>Strengths:</strong></p>
<ul>
<li>‚úÖ Clear chain of accountability</li>
<li>‚úÖ Legally mandated oversight</li>
<li>‚úÖ Court-tested defensibility</li>
<li>‚úÖ Low cost (built into hierarchy)</li>
</ul>
<p><strong>Weaknesses:</strong></p>
<ul>
<li>‚ùå Potential for hierarchical bias</li>
<li>‚ùå Limited statistical validation</li>
<li>‚ùå Variability across forces</li>
<li>‚ùå Reactive rather than predictive</li>
</ul>
<p><strong>Best for:</strong> Volume investigations, criminal cases requiring court presentation, regulatory compliance</p>
<hr>
<h3 id="2-journalism-quality-control">2. Journalism Quality Control</h3>
<p><strong>Framework:</strong> Multi-layered editorial process</p>
<ol>
<li>Planning (editor approval)</li>
<li>Research (source verification)</li>
<li>Writing (first draft)</li>
<li>Editing (line-by-line review)</li>
<li>Fact-checking (independent verification of every fact)</li>
<li>Legal review (libel, source protection)</li>
<li>Publication</li>
</ol>
<p><strong>Magazine Model:</strong></p>
<ul>
<li>Separate fact-checker (not writer or editor)</li>
<li>Verifies every factual claim</li>
<li>Re-interviews sources</li>
<li>Checks arithmetic and logic</li>
<li>Documents source for each assertion</li>
</ul>
<p><strong>Strengths:</strong></p>
<ul>
<li>‚úÖ Extremely thorough verification</li>
<li>‚úÖ Independent fact-checking</li>
<li>‚úÖ Multiple expert reviews (editorial, legal, subject matter)</li>
<li>‚úÖ Strong reputation protection</li>
</ul>
<p><strong>Weaknesses:</strong></p>
<ul>
<li>‚ùå Very time-intensive (weeks to months)</li>
<li>‚ùå High cost (multiple full-time roles)</li>
<li>‚ùå Not scalable to large document sets</li>
<li>‚ùå Subjective standards (no statistical validation)</li>
</ul>
<p><strong>Best for:</strong> High-impact investigations, legal risk stories, reputation-critical reporting, limited document volume</p>
<hr>
<h3 id="3-legal-ediscovery-quality-control">3. Legal eDiscovery Quality Control</h3>
<p><strong>Framework:</strong> Statistical validation with sampling</p>
<p><strong>TAR 1.0 Validation:</strong></p>
<ul>
<li>Random sample of unreviewed documents</li>
<li>Senior attorney review of sample</li>
<li>Calculate precision (% relevant in high-scoring docs)</li>
<li>Calculate recall (% of relevant docs captured)</li>
<li>Target: 75%+ recall, high precision</li>
</ul>
<p><strong>TAR 2.0/CAL Quality Control:</strong></p>
<ul>
<li>Continuous validation throughout review</li>
<li>Real-time accuracy metrics</li>
<li>Elusion testing (sample documents system ranked as non-relevant)</li>
<li>Statistical confidence intervals</li>
</ul>
<p><strong>Batching QC:</strong></p>
<ul>
<li>Senior attorney reviews 5-10% of junior attorney work</li>
<li>Measure consistency across reviewers</li>
<li>Targeted feedback and re-training</li>
<li>Document QC results for defensibility</li>
</ul>
<p><strong>Strengths:</strong></p>
<ul>
<li>‚úÖ Statistically rigorous</li>
<li>‚úÖ Court-validated methodology</li>
<li>‚úÖ Scalable to millions of documents</li>
<li>‚úÖ Automated measurement</li>
<li>‚úÖ Clear metrics (precision/recall)</li>
</ul>
<p><strong>Weaknesses:</strong></p>
<ul>
<li>‚ùå Requires statistical expertise</li>
<li>‚ùå Upfront seed set quality critical (TAR 1.0)</li>
<li>‚ùå Expensive platforms (Relativity, Everlaw)</li>
<li>‚ùå Can miss subtle context</li>
</ul>
<p><strong>Best for:</strong> Large-scale document review, litigation, regulatory investigations, compliance</p>
<hr>
<h3 id="4-regulatory-investigation-quality-control">4. Regulatory Investigation Quality Control</h3>
<p><strong>Framework:</strong> Dual decision-maker model</p>
<p><strong>Composition:</strong></p>
<ul>
<li>One professional member (same discipline as registrant)</li>
<li>One lay member (not from regulated profession)</li>
<li>Often: legal assessor for procedure</li>
</ul>
<p><strong>Real Prospect Test:</strong></p>
<ul>
<li>&quot;Is there a real prospect that a tribunal/panel would find facts proved?&quot;</li>
<li>Low threshold (not &quot;balance of probabilities&quot;)</li>
<li>Two independent assessors must agree</li>
</ul>
<p><strong>Case Examiner Review (GMC/HCPC):</strong></p>
<ul>
<li>Both examiners review same evidence</li>
<li>Independent conclusions</li>
<li>If disagree ‚Üí Investigation Committee Panel</li>
<li>Rationale documented for transparency</li>
</ul>
<p><strong>Strengths:</strong></p>
<ul>
<li>‚úÖ Balances technical expertise and public perspective</li>
<li>‚úÖ Prevents professional bias/closing ranks</li>
<li>‚úÖ Legally mandated composition</li>
<li>‚úÖ Transparent decision-making</li>
</ul>
<p><strong>Weaknesses:</strong></p>
<ul>
<li>‚ùå Slower (coordination of two busy professionals)</li>
<li>‚ùå Potential for lay/professional tension</li>
<li>‚ùå Limited to professional standards contexts</li>
<li>‚ùå No statistical validation</li>
</ul>
<p><strong>Best for:</strong> Professional misconduct, fitness-to-practise, standards breaches, public protection cases</p>
<hr>
<h3 id="5-intelligence-analysis-quality-control">5. Intelligence Analysis Quality Control</h3>
<p><strong>Framework:</strong> Structured analytic review + Red Team</p>
<p><strong>ICD 203 Requirements:</strong></p>
<ul>
<li>Describes quality/credibility of sources</li>
<li>Expresses uncertainties (WEP + confidence levels)</li>
<li>Distinguishes intelligence from assumptions</li>
<li>Incorporates analysis of alternatives</li>
<li>Uses clear argumentation</li>
<li>Explains changes in judgments</li>
</ul>
<p><strong>Red Cell Review:</strong></p>
<ul>
<li>Separate unit constructs alternative interpretations</li>
<li>Adversarial analysis of draft assessments</li>
<li>Devil&#39;s Advocacy institutionalized</li>
<li>Not consensus-seeking</li>
</ul>
<p><strong>Minimum 3 Reviewers:</strong></p>
<ul>
<li>Intelligence Community research: 3+ independent raters required for reliable quality control</li>
<li>Mitigates individual analyst biases</li>
<li>Collective analysis more accurate than individuals</li>
</ul>
<p><strong>Strengths:</strong></p>
<ul>
<li>‚úÖ Institutionalized contrarian analysis</li>
<li>‚úÖ Multiple independent perspectives</li>
<li>‚úÖ Structured techniques combat bias</li>
<li>‚úÖ Clear confidence/uncertainty expression</li>
</ul>
<p><strong>Weaknesses:</strong></p>
<ul>
<li>‚ùå Time-intensive (multiple reviews)</li>
<li>‚ùå Can delay urgent intelligence</li>
<li>‚ùå Classified processes (less peer scrutiny)</li>
<li>‚ùå Research shows limited bias reduction from some SATs</li>
</ul>
<p><strong>Best for:</strong> High-stakes decisions, incomplete information, adversarial contexts, national security</p>
<hr>
<h3 id="6-academic-research-quality-control">6. Academic Research Quality Control</h3>
<p><strong>Framework:</strong> Inter-rater reliability + peer review</p>
<p><strong>Dual Independent Coding:</strong></p>
<ul>
<li>Two researchers code same data independently</li>
<li>Calculate Cohen&#39;s Kappa (agreement measure)</li>
<li>‚â•0.60 acceptable, ‚â•0.70 preferred</li>
<li>Discuss discrepancies, refine codebook</li>
<li>Re-code until agreement acceptable</li>
</ul>
<p><strong>Cohen&#39;s Kappa Calculation:</strong></p>
<ul>
<li>Accounts for chance agreement (unlike simple % agreement)</li>
<li>Formula: Œ∫ = (Observed Agreement - Expected Agreement) / (1 - Expected Agreement)</li>
<li>Interpretation: &lt;0.20 slight, 0.21-0.40 fair, 0.41-0.60 moderate, 0.61-0.80 substantial, 0.81-1.00 almost perfect</li>
</ul>
<p><strong>Consensus Coding Process:</strong></p>
<ol>
<li>Independent coding of subset (10-20%)</li>
<li>Calculate IRR (Cohen&#39;s Kappa)</li>
<li>Meet to discuss disagreements</li>
<li>Refine codebook definitions</li>
<li>Re-code problematic segments</li>
<li>Iterate until ‚â•0.60 achieved</li>
<li>Apply finalized codebook to full dataset</li>
</ol>
<p><strong>Peer Review (Publication):</strong></p>
<ul>
<li>Minimum 2 external reviewers</li>
<li>Expert in methodology and topic</li>
<li>Blind review (double or single)</li>
<li>Editor adjudicates disagreements</li>
<li>Revision rounds before acceptance</li>
</ul>
<p><strong>Strengths:</strong></p>
<ul>
<li>‚úÖ Statistically validated reliability</li>
<li>‚úÖ Transparent methodology (replicable)</li>
<li>‚úÖ External peer review pre-publication</li>
<li>‚úÖ Audit trail (codebook, memos, IRR calculations)</li>
</ul>
<p><strong>Weaknesses:</strong></p>
<ul>
<li>‚ùå Time-intensive (months to years)</li>
<li>‚ùå Limited to academic research contexts</li>
<li>‚ùå IRR may not capture quality of disagreements</li>
<li>‚ùå Kappa sensitive to prevalence (low when one code dominates)</li>
</ul>
<p><strong>Best for:</strong> Research studies, systematic reviews, qualitative analysis, academic publications</p>
<hr>
<h2 id="cross-domain-quality-control-patterns">Cross-Domain Quality Control Patterns</h2>
<h3 id="universal-principles">Universal Principles</h3>
<ol>
<li><strong>Independence</strong>: QC reviewer should not be original analyst (except self-review with documented process)</li>
<li><strong>Documentation</strong>: All QC activities logged with timestamp, reviewer, findings</li>
<li><strong>Feedback Loops</strong>: Results inform training, process improvement, recalibration</li>
<li><strong>Proportionality</strong>: QC rigor matched to stakes (higher scrutiny for higher-impact conclusions)</li>
<li><strong>Transparency</strong>: QC methodology disclosed to consumers of analysis</li>
</ol>
<h3 id="convergent-practices">Convergent Practices</h3>
<table>
<thead>
<tr>
<th>Practice</th>
<th>Police</th>
<th>Journalism</th>
<th>Legal</th>
<th>Regulatory</th>
<th>Intelligence</th>
<th>Academic</th>
</tr>
</thead>
<tbody><tr>
<td><strong>Multiple reviewers</strong></td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><strong>Documented rationale</strong></td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><strong>Independent oversight</strong></td>
<td>‚úÖ (IOPC)</td>
<td>‚úÖ (Legal)</td>
<td>‚úÖ (Judge/Opposing counsel)</td>
<td>‚úÖ (Lay member)</td>
<td>‚úÖ (Red Cell)</td>
<td>‚úÖ (Peer review)</td>
</tr>
<tr>
<td><strong>Statistical validation</strong></td>
<td>‚ùå</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>‚ùå</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><strong>Sampling strategy</strong></td>
<td>üü° (Ad hoc)</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
<td>‚ùå</td>
<td>üü°</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><strong>Calibration exercises</strong></td>
<td>üü°</td>
<td>‚ùå</td>
<td>‚úÖ</td>
<td>üü°</td>
<td>‚úÖ</td>
<td>‚úÖ</td>
</tr>
<tr>
<td><strong>Blind review</strong></td>
<td>‚ùå</td>
<td>‚ùå</td>
<td>üü° (Redacted)</td>
<td>‚ùå</td>
<td>üü°</td>
<td>‚úÖ</td>
</tr>
</tbody></table>
<hr>
<h2 id="implementation-for-phronesis-fcip">Implementation for Phronesis FCIP</h2>
<h3 id="recommended-multi-layered-qc-architecture">Recommended Multi-Layered QC Architecture</h3>
<p><strong>Layer 1: Automated Quality Checks</strong></p>
<ul>
<li>Completeness validation (all required fields populated)</li>
<li>Consistency checks (contradictory findings flagged)</li>
<li>Timeline coherence (events in logical sequence)</li>
<li>Citation verification (every finding linked to evidence)</li>
<li>Source reliability scoring (Admiralty Code)</li>
</ul>
<p><strong>Layer 2: Peer Review</strong></p>
<ul>
<li>Minimum 2 independent reviewers</li>
<li>Calibration on initial cases (calculate IRR)</li>
<li>Targeted review (high-impact findings get more scrutiny)</li>
<li>Documented disagreements and resolutions</li>
</ul>
<p><strong>Layer 3: Red Team Analysis</strong></p>
<ul>
<li>Devil&#39;s Advocacy mode (argue against findings)</li>
<li>Alternative hypothesis testing (ACH matrix)</li>
<li>Assumption challenge (Key Assumptions Check)</li>
<li>Bias detection (motivated reasoning patterns)</li>
</ul>
<p><strong>Layer 4: Statistical Validation (Large-Scale)</strong></p>
<ul>
<li>Random sample of AI-flagged findings</li>
<li>Expert validation of sample</li>
<li>Calculate precision/recall</li>
<li>Confidence intervals on estimates</li>
<li>Elusion testing (check false negatives)</li>
</ul>
<p><strong>Layer 5: External Review</strong></p>
<ul>
<li>Subject matter experts for complex cases</li>
<li>Legal review for high-risk conclusions</li>
<li>Methodology review for novel analysis</li>
<li>Stakeholder review (when appropriate)</li>
</ul>
<h3 id="qc-metrics-dashboard">QC Metrics Dashboard</h3>
<p>Display for each investigation:</p>
<ul>
<li><strong>Completeness</strong>: % of required evidence types collected</li>
<li><strong>Consistency</strong>: # of unresolved contradictions</li>
<li><strong>Coverage</strong>: % of documents analyzed by engines</li>
<li><strong>Confidence</strong>: Aggregate confidence score (weighted by finding severity)</li>
<li><strong>Review Status</strong>: Reviewers assigned, completion %</li>
<li><strong>IRR</strong>: Cohen&#39;s Kappa for dual-coded findings</li>
<li><strong>Validation</strong>: Precision/recall if sampled</li>
<li><strong>Red Team</strong>: Alternative hypotheses considered, disposition</li>
</ul>
<h3 id="decision-rules">Decision Rules</h3>
<p><strong>Proceed to Report:</strong></p>
<ul>
<li>All automated checks pass</li>
<li>Minimum 2 reviewers completed (Kappa ‚â•0.60)</li>
<li>Red Team review completed</li>
<li>No unresolved high-severity contradictions</li>
</ul>
<p><strong>Require Additional Review:</strong></p>
<ul>
<li>IRR &lt;0.60 (recalibrate, recode)</li>
<li>Red Team identifies plausible alternative not considered</li>
<li>Legal risk flagged</li>
<li>Novel methodology applied</li>
</ul>
<p><strong>Escalate to Expert:</strong></p>
<ul>
<li>Contradictory expert opinions</li>
<li>Complex technical/scientific questions</li>
<li>Unprecedented factual scenarios</li>
<li>Potential systemic institutional failure</li>
</ul>
<hr>
<h2 id="cost-benefit-analysis">Cost-Benefit Analysis</h2>
<h3 id="time-investment-typical">Time Investment (Typical)</h3>
<table>
<thead>
<tr>
<th>Domain</th>
<th>QC Time (% of total investigation)</th>
<th>Bottleneck</th>
<th>Mitigation</th>
</tr>
</thead>
<tbody><tr>
<td>Police</td>
<td>10-15%</td>
<td>Supervisor availability</td>
<td>Stagger review, automate routine checks</td>
</tr>
<tr>
<td>Journalism</td>
<td>40-60%</td>
<td>Fact-checking bandwidth</td>
<td>Prioritize high-risk claims, tool-assisted verification</td>
</tr>
<tr>
<td>Legal</td>
<td>20-30%</td>
<td>Senior attorney time</td>
<td>Statistical sampling, TAR elusion testing</td>
</tr>
<tr>
<td>Regulatory</td>
<td>25-35%</td>
<td>Dual examiner coordination</td>
<td>Async review with structured decision points</td>
</tr>
<tr>
<td>Intelligence</td>
<td>30-50%</td>
<td>Red Cell/reviewer availability</td>
<td>Lightweight SATs first, deep review for key judgments</td>
</tr>
<tr>
<td>Academic</td>
<td>50-70%</td>
<td>Dual coding, peer review</td>
<td>Reliability sampling (not 100% dual-coding)</td>
</tr>
</tbody></table>
<h3 id="error-cost-vs-qc-cost-trade-off">Error Cost vs. QC Cost Trade-off</h3>
<p><strong>High-Stakes (Serious Misconduct, Criminal Charges):</strong></p>
<ul>
<li>Accept 50-70% QC overhead</li>
<li>Use academic-level rigor (dual coding, peer review)</li>
<li>Statistical validation where applicable</li>
<li>External expert review</li>
</ul>
<p><strong>Medium-Stakes (Professional Standards, Civil Matters):</strong></p>
<ul>
<li>20-40% QC overhead</li>
<li>Regulatory dual-examiner model</li>
<li>Sampling approach for large volumes</li>
<li>Internal peer review</li>
</ul>
<p><strong>Low-Stakes (Preliminary Assessment, Triage):</strong></p>
<ul>
<li>10-20% QC overhead</li>
<li>Single senior reviewer</li>
<li>Automated checks + spot sampling</li>
<li>Fast feedback for recalibration</li>
</ul>
<hr>
<h2 id="selecting-qc-methodology">Selecting QC Methodology</h2>
<h3 id="decision-tree">Decision Tree</h3>
<p><strong>1. What is the volume of evidence?</strong></p>
<ul>
<li><strong>Small (&lt;100 docs)</strong>: Manual review, journalism/academic methods</li>
<li><strong>Medium (100-10,000 docs)</strong>: Legal sampling, regulatory dual-review</li>
<li><strong>Large (10,000+ docs)</strong>: Legal TAR/CAL with statistical validation</li>
</ul>
<p><strong>2. What are the stakes?</strong></p>
<ul>
<li><strong>High (criminal, professional license, major institutional change)</strong>: Academic IRR + journalism fact-checking + legal validation</li>
<li><strong>Medium (civil liability, reputation risk)</strong>: Regulatory dual-examiner + legal sampling</li>
<li><strong>Low (internal assessment, preliminary)</strong>: Police supervisory model</li>
</ul>
<p><strong>3. What is the time constraint?</strong></p>
<ul>
<li><strong>Urgent (&lt;1 week)</strong>: Police supervisory + automated checks</li>
<li><strong>Normal (1-4 weeks)</strong>: Legal sampling or regulatory dual-review</li>
<li><strong>Extended (months)</strong>: Academic IRR + journalism fact-checking</li>
</ul>
<p><strong>4. What is adversarial intensity?</strong></p>
<ul>
<li><strong>High (litigation, public scrutiny)</strong>: Legal statistical validation + Red Team</li>
<li><strong>Medium (regulatory proceeding)</strong>: Dual-examiner + peer review</li>
<li><strong>Low (internal)</strong>: Supervisory review + automated checks</li>
</ul>
<p><strong>5. What is the evidence type?</strong></p>
<ul>
<li><strong>Documentary</strong>: Legal TAR/CAL methods</li>
<li><strong>Testimonial</strong>: Police PEACE/Cognitive Interview + journalism verification</li>
<li><strong>Mixed</strong>: Regulatory + intelligence SATs</li>
</ul>
<hr>
<h2 id="quality-control-integration-with-sam-framework">Quality Control Integration with S.A.M. Framework</h2>
<h3 id="qc-for-each-contradiction-type">QC for Each Contradiction Type</h3>
<table>
<thead>
<tr>
<th>S.A.M. Type</th>
<th>Primary QC Method</th>
<th>Validation Technique</th>
<th>Threshold</th>
</tr>
</thead>
<tbody><tr>
<td><strong>SELF</strong></td>
<td>Automated logic check</td>
<td>Independent reviewer confirmation</td>
<td>100% reviewed if high-severity</td>
</tr>
<tr>
<td><strong>INTER_DOC</strong></td>
<td>Timeline overlay + peer review</td>
<td>Statistical sampling if &gt;100 docs</td>
<td>Kappa ‚â•0.60 on contradictions</td>
</tr>
<tr>
<td><strong>TEMPORAL</strong></td>
<td>Chronology verification</td>
<td>External timeline validation</td>
<td>All dates source-verified</td>
</tr>
<tr>
<td><strong>EVIDENTIARY</strong></td>
<td>Evidence hierarchy check</td>
<td>Expert review if complex</td>
<td>Dual-review for key gaps</td>
</tr>
<tr>
<td><strong>MODALITY_SHIFT</strong></td>
<td>Linguistic analysis + peer review</td>
<td>Red Team challenge</td>
<td>Document all certainty shifts</td>
</tr>
<tr>
<td><strong>SELECTIVE_CITATION</strong></td>
<td>Citation network analysis</td>
<td>Random sampling of uncited material</td>
<td>Sample ‚â•30 or 10% (whichever larger)</td>
</tr>
<tr>
<td><strong>SCOPE_SHIFT</strong></td>
<td>Scope boundary documentation</td>
<td>Legal review</td>
<td>All shifts explicitly justified</td>
</tr>
<tr>
<td><strong>UNEXPLAINED_CHANGE</strong></td>
<td>Version comparison + timeline</td>
<td>Journalism verification protocol</td>
<td>Every position change sourced</td>
</tr>
</tbody></table>
<hr>
<h2 id="continuous-improvement">Continuous Improvement</h2>
<h3 id="qc-metrics-to-track">QC Metrics to Track</h3>
<ol>
<li><strong>False Positive Rate</strong>: % of flagged issues that were not actual problems (calibration metric)</li>
<li><strong>False Negative Rate</strong>: % of issues missed in initial review (elusion testing)</li>
<li><strong>Reviewer Agreement</strong>: Cohen&#39;s Kappa trend over time (should increase as calibration improves)</li>
<li><strong>Time to QC</strong>: Duration from analysis complete to QC sign-off (efficiency metric)</li>
<li><strong>Rework Rate</strong>: % of investigations requiring significant revision after QC (quality metric)</li>
<li><strong>Challenge Success</strong>: % of Red Team challenges that changed conclusions (rigor metric)</li>
</ol>
<h3 id="calibration-protocol">Calibration Protocol</h3>
<p><strong>Monthly:</strong></p>
<ul>
<li>Calculate IRR on random sample of dual-reviewed cases</li>
<li>Targeted training if Kappa drops below 0.60</li>
<li>Update QC guidelines based on common disagreements</li>
</ul>
<p><strong>Quarterly:</strong></p>
<ul>
<li>External expert review of 3-5 completed investigations</li>
<li>Blind review (expert doesn&#39;t know original conclusions)</li>
<li>Compare expert vs. system findings</li>
<li>Identify systematic biases</li>
</ul>
<p><strong>Annually:</strong></p>
<ul>
<li>Full methodology audit</li>
<li>Benchmark against industry standards</li>
<li>Update QC procedures based on lessons learned</li>
<li>Publish methodology transparency report</li>
</ul>
<hr>
<h2 id="further-reading">Further Reading</h2>
<p><strong>Police:</strong></p>
<ul>
<li><a href="/research/methodologies/01-police-investigations/">Police Investigation Workflows</a> - Section 8: Quality Assurance</li>
</ul>
<p><strong>Journalism:</strong></p>
<ul>
<li><a href="/research/methodologies/02-journalism-investigations/">Investigative Journalism Methods</a> - Section 12: Quality Control</li>
</ul>
<p><strong>Legal:</strong></p>
<ul>
<li><a href="/research/methodologies/03-legal-ediscovery/">Legal eDiscovery Workflows</a> - Section 3: TAR Validation</li>
</ul>
<p><strong>Regulatory:</strong></p>
<ul>
<li><a href="/research/methodologies/04-regulatory-investigations/">Regulatory Investigations</a> - Section 6: Expert Review</li>
</ul>
<p><strong>Intelligence:</strong></p>
<ul>
<li><a href="/research/methodologies/05-intelligence-analysis/">Intelligence Analysis Methods</a> - Section 5: Bias Mitigation</li>
</ul>
<p><strong>Academic:</strong></p>
<ul>
<li><a href="/research/methodologies/06-academic-research/">Academic Research Methods</a> - Section 6: Inter-Rater Reliability</li>
</ul>
<hr>
<p><strong>Last Updated:</strong> January 2026
<strong>Purpose:</strong> Quality control methodology selection and implementation guidance
<strong>Target Audience:</strong> Platform developers, investigators, quality assurance teams
<strong>Integration:</strong> Phronesis FCIP quality control architecture</p>

          <div class="doc-footer">
            <a class="btn btn-secondary" href="/research/">Back to Research Hub</a>
            <a class="btn btn-ghost" href="https://github.com/apatheia-labs/phronesis/blob/main/website/research/QUALITY-CONTROL-COMPARISON.md" target="_blank" rel="noopener noreferrer">View Source Markdown</a>
          </div>
        </article>
      </div>
    </section>
  </main>

  <footer>
    <div class="container">
      <div class="footer-content">
        <div class="footer-brand">
          <a href="/" class="logo">
            <div class="logo-icon">A</div>
            <div class="logo-text">
              <span class="logo-brand">APATHEIA LABS</span>
              <span class="logo-tagline">Clarity Without Distortion</span>
            </div>
          </a>
          <p>Building tools for institutional accountability.</p>
        </div>
        <div class="footer-links">
          <a href="/research/">Research</a>
          <a href="https://github.com/apatheia-labs/phronesis" target="_blank" rel="noopener noreferrer">GitHub</a>
          <a href="https://github.com/apatheia-labs/phronesis/issues" target="_blank" rel="noopener noreferrer">Report Issues</a>
          <a href="mailto:contact@apatheia.io">Contact</a>
        </div>
      </div>
    </div>
  </footer>

</body>
</html>
